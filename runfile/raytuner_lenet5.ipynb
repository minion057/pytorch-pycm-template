{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb9a009-f257-4345-b1ea-d1a2026e0c84",
   "metadata": {},
   "source": [
    "# 0. Set up preparation\n",
    "## Auto-Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d49dfe-ebc5-4783-81cf-aacf5f11888b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 파이썬 코드를 실행하기 전에 항상 모든 모듈을 Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7622416-9f2b-4b5c-a53d-5e8f7e39cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/x3093a03/workspace/pycmWraytune\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "# module path\n",
    "module_dir = '/scratch/x3093a03/workspace/pycmWraytune'\n",
    "\n",
    "sys.path.append(module_dir)\n",
    "print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80117350-408e-4149-81e4-da26965e4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchinfo import summary\n",
    "import model.model as module_arch\n",
    "\n",
    "from torchvision import transforms\n",
    "import data_loader.transforms as module_transforms\n",
    "import data_loader.npz_loaders as module_data\n",
    "import model.optim as module_optim\n",
    "import model.lr_scheduler as module_lr_scheduler\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "\n",
    "from parse_config import ConfigParser\n",
    "from runner import Trainer\n",
    "from utils import prepare_device, reset_device, fix_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b64158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import ray\n",
    "from ray import tune as raytune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import get_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb2d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "# SEED = 123\n",
    "# torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# np.random.seed(SEED)\n",
    "fix_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec9db14-a705-4fbf-91c2-a38ab332cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_tune(config, train_config):\n",
    "    logger = train_config.get_logger('train')\n",
    "    \n",
    "    # setup data_loader instances\n",
    "    if 'trsfm' in train_config['data_loader']['args'].keys():\n",
    "        tf_list = []\n",
    "        for k, v in train_config['data_loader']['args']['trsfm'].items():\n",
    "            if v is None: tf_list.append(getattr(module_transforms, k)())\n",
    "            else: tf_list.append(getattr(module_transforms, k)(**v))\n",
    "        train_config['data_loader']['args']['trsfm'] = transforms.Compose(tf_list)\n",
    "    ''' raytune '''\n",
    "    if 'batch_size' in config.keys():\n",
    "        train_config['data_loader']['args']['batch_size'] = config['batch_size']\n",
    "    data_loader = train_config.init_obj('data_loader', module_data)\n",
    "    train_data_loader = data_loader.loaderdict['train'].dataloader\n",
    "    valid_data_loader = data_loader.loaderdict['valid'].dataloader\n",
    "\n",
    "    # build model architecture, then print to console\n",
    "    classes = train_data_loader.dataset.classes\n",
    "    ''' raytune '''\n",
    "    if 'dropout' in config.keys():\n",
    "        train_config['arch']['args']['drop_rate'] = config['dropout']\n",
    "    model = train_config.init_obj('arch', module_arch)\n",
    "    \n",
    "    # prepare for (multi-device) GPU training\n",
    "    device, device_ids = prepare_device(train_config['n_gpu'])\n",
    "    model = model.to(device)\n",
    "    if len(device_ids) > 1: model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "    # get function handles of loss and metrics\n",
    "    ''' raytune '''\n",
    "    # criterion = getattr(module_loss, train_config['loss'])\n",
    "    if 'loss' in config.keys(): criterion = getattr(module_loss, config['loss'])\n",
    "    else: criterion = getattr(module_loss, train_config['loss'])\n",
    "    metrics = [getattr(module_metric, met) for met in train_config['metrics'].keys()]    \n",
    "        \n",
    "    # build optimizer, learning rate scheduler. delete every lines containing lr_scheduler for disabling scheduler\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    ''' raytune '''\n",
    "    if 'otimp' in config.keys():\n",
    "        train_config['optimizer']['type'] = config['otimp']\n",
    "    if 'lr' in config.keys():\n",
    "        train_config['optimizer']['args']['lr'] = config['lr']\n",
    "    if 'weight_decay' in config.keys():\n",
    "        train_config['optimizer']['args']['weight_decay'] = config['weight_decay']\n",
    "    \n",
    "    optimizer = train_config.init_obj('optimizer', module_optim, trainable_params)\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    if 'lr_scheduler' in train_config.config.keys():\n",
    "        lr_scheduler = train_config.init_obj('lr_scheduler', module_lr_scheduler, optimizer)\n",
    "    if lr_scheduler is None: print('lr_scheduler is not set.\\n')\n",
    "\n",
    "    ''' raytune '''\n",
    "    train_config['trainer']['epochs'] = MAXEPOCHS\n",
    "    train_config['trainer']['early_stop'] = MAXEPOCHS\n",
    "    train_config['trainer']['tensorboard'] = False\n",
    "    train_config['trainer']['tensorboard_projector']['train'] = False\n",
    "    train_config['trainer']['tensorboard_projector']['valid'] = False\n",
    "    train_config['trainer']['tensorboard_pred_plot'] = False\n",
    "    train_config['trainer']['save_performance_plot'] = True\n",
    "\n",
    "\n",
    "    train_kwargs = {\n",
    "        'model': model,\n",
    "        'criterion': criterion,\n",
    "        'metric_ftns': metrics,\n",
    "        'plottable_metric_ftns': None,\n",
    "        'optimizer': optimizer,\n",
    "        'lr_scheduler': lr_scheduler,\n",
    "        'config': train_config,\n",
    "        'classes': classes,\n",
    "        'device': device,\n",
    "        'data_loader': train_data_loader,\n",
    "        'valid_data_loader': valid_data_loader,\n",
    "        'da_ftns': None,\n",
    "        'raytune':True\n",
    "    }\n",
    "    trainer = Trainer(**train_kwargs)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # print the model infomation\n",
    "    # Option. Use after training because data flows into the model and calculates it\n",
    "    use_data = next(iter(train_data_loader))[0].to(device)\n",
    "    input_size = use_data.shape\n",
    "    logger.info('\\nInput_size: {}'.format(input_size))\n",
    "    model_info = str(summary(model, input_size=input_size, verbose=0))\n",
    "    logger.info('{}\\n'.format(model_info))\n",
    "\n",
    "    reset_device('cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c82a99-0edf-4257-b9c1-e952ef3c2c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting epoch: 100\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser(description='PyTorch Template')\n",
    "config_path = '/scratch/x3093a03/workspace/pycmWraytune/config/lenet5.json'\n",
    "args.add_argument('-c', '--config', default=config_path, type=str, help='config file path (default: None)')\n",
    "args.add_argument('-r', '--resume', default=None, type=str, help='path to latest checkpoint (default: None)')\n",
    "args.add_argument('-d', '--device', default='0, 1', type=str, help='indices of GPUs to enable (default: all)')\n",
    "args.add_argument('-t', '--test', default=False, type=bool, help='Whether to enable test mode (default: False)')\n",
    "\n",
    "# custom cli options to modify configuration from default values given in json file.\n",
    "CustomArgs = collections.namedtuple('CustomArgs', 'flags type target')\n",
    "options = [\n",
    "    CustomArgs(['--lr', '--learning_rate'], type=float, target='optimizer;args;lr'),\n",
    "    CustomArgs(['--bs', '--batch_size'], type=int, target='data_loader;args;batch_size')\n",
    "]\n",
    "train_config = ConfigParser.from_args(args, options)\n",
    "print(f\"setting epoch: {train_config['trainer']['epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95905722-4285-41c4-8412-a12faa7bf8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXEPOCHS = 10\n",
    "\n",
    "ray_tune_config = {\n",
    "    \"batch_size\": raytune.choice([8, 16, 32, 64, 128, 512]),\n",
    "    # \"dropout\": raytune.choice([0, 0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "    \"loss\": raytune.choice(['ce_loss', 'bce_loss']),\n",
    "    \"otimp\": raytune.choice(['AdamW', 'Lamb', 'Lion']),\n",
    "    \"lr\": raytune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": raytune.choice([0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "}\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"BACC\",\n",
    "    mode=\"max\",\n",
    "    max_t=MAXEPOCHS,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd148d43-f459-4a8d-9f1a-359c5fbd6b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = raytune.run(\n",
    "    partial(ray_tune, train_config=train_config),\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    "    config=ray_tune_config,\n",
    "    num_samples=50,\n",
    "    scheduler=scheduler,\n",
    "    storage_path=\"/scratch/x3093a03/result/raytune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649607d-4791-4db9-9e18-1b3e9e6c9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = result.get_best_trial(\"BACC\", \"max\", \"last\")\n",
    "best_trial\n",
    "\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation Baccuracy: {best_trial.last_result['BACC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403f522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apple",
   "language": "python",
   "name": "apple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
